import org.apache.spark.sql.SparkSession
import com.typesafe.scalalogging.LazyLogging
import layers.BronzeLayer

/**
 * Application principale d'analyse des restaurants Uber Eats
 * Architecture mÃ©daillon : Bronze â†’ Silver â†’ Gold
 */
object RestaurantAnalysisApp extends LazyLogging {

  def main(args: Array[String]): Unit = {
    logger.info("ğŸ½ï¸ DÃ©marrage de l'analyse des restaurants Uber Eats")    // CrÃ©ation de la session Spark
    implicit val spark: SparkSession = SparkSession.builder()
      .appName("Uber Eats Restaurant Analysis")
      .master("local[*]")
      .config("spark.sql.adaptive.enabled", "true")
      .config("spark.sql.adaptive.coalescePartitions.enabled", "true")
      .getOrCreate()

    // Configuration du niveau de log
    spark.sparkContext.setLogLevel("WARN")

    try {
      logger.info("ğŸ—ï¸ Architecture mÃ©daillon - Pipeline de donnÃ©es")

      // === COUCHE BRONZE ===
      logger.info("ğŸ¥‰ ExÃ©cution de la couche Bronze")
      val bronzeSuccess = BronzeLayer.run()

      if (bronzeSuccess) {
        logger.info("âœ… Couche Bronze terminÃ©e avec succÃ¨s")
        
        // TODO: ImplÃ©menter les couches Silver et Gold
        logger.info("ğŸ¥ˆ Couche Silver - Ã€ implÃ©menter")
        logger.info("ğŸ¥‡ Couche Gold - Ã€ implÃ©menter")
        
        logger.info("ğŸ‰ Pipeline d'analyse terminÃ© avec succÃ¨s")
      } else {
        logger.error("âŒ Ã‰chec de la couche Bronze - ArrÃªt du pipeline")
      }

    } catch {
      case e: Exception =>
        logger.error(s"ğŸ’¥ Erreur dans l'application : ${e.getMessage}")
        e.printStackTrace()
    } finally {
      // ArrÃªt de la session Spark
      spark.stop()
      logger.info("ğŸ”š Application terminÃ©e")
    }
  }
}
